{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hyperparameters_ga.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_5HvmoYJx2W",
        "colab_type": "code",
        "outputId": "26a4d326-4898-4e08-c87d-b1af43887100",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "!pip install deap"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: deap in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from deap) (1.18.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNSEzY_pvcXl",
        "colab_type": "code",
        "outputId": "c6579776-a2ea-4cdb-ff25-88429ffc5c21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "from deap import base\n",
        "from deap import creator\n",
        "from deap import tools\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import numpy\n",
        "import elitism\n",
        "\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from sklearn import model_selection\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "from sklearn.utils.testing import ignore_warnings\n",
        "from math import floor"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.utils.testing module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.utils. Anything that cannot be imported from sklearn.utils is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6Ps7K_xtgUH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MlpHyperparametersTest:\n",
        "\n",
        "    NUM_FOLDS = 5\n",
        "\n",
        "    def __init__(self, randomSeed):\n",
        "\n",
        "        self.randomSeed = randomSeed\n",
        "        self.initDataset()\n",
        "        self.kfold = model_selection.KFold(n_splits=self.NUM_FOLDS, random_state=self.randomSeed)\n",
        "\n",
        "    def initDataset(self):\n",
        "        \n",
        "        (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "        self.X = numpy.vstack((x_train,x_test))\n",
        "        self.X = self.X / 255.0\n",
        "        self.X = self.X.reshape(self.X.shape[0], -1)\n",
        "        y_train = y_train.reshape(-1, 1)\n",
        "        y_test = y_test.reshape(-1, 1)\n",
        "        self.y = numpy.vstack((y_train,y_test))        \n",
        "        self.y = self.y.flatten()\n",
        "\n",
        "    def convertParams(self, params):\n",
        "\n",
        "        if round(params[1]) <= 0:\n",
        "            hiddenLayerSizes = round(params[0]),\n",
        "        elif round(params[2]) <= 0:\n",
        "            hiddenLayerSizes = (round(params[0]), round(params[1]))\n",
        "        elif round(params[3]) <= 0:\n",
        "            hiddenLayerSizes = (round(params[0]), round(params[1]), round(params[2]))\n",
        "        else:\n",
        "            hiddenLayerSizes = (round(params[0]), round(params[1]), round(params[2]), round(params[3]))\n",
        "\n",
        "        learning_rate_init = numpy.power(10, params[4])\n",
        "        solver = ['sgd', 'adam'][floor(params[5])]        \n",
        "        return hiddenLayerSizes, learning_rate_init, solver\n",
        "        \n",
        "    @ignore_warnings(category=ConvergenceWarning)\n",
        "    def getAccuracy(self, params):\n",
        "        hiddenLayerSizes, learning_rate_init, solver = self.convertParams(params)\n",
        "        self.classifier = MLPClassifier(random_state=self.randomSeed,\n",
        "                                        hidden_layer_sizes=hiddenLayerSizes,\n",
        "                                        activation='relu',\n",
        "                                        solver=solver,\n",
        "                                        learning_rate_init=learning_rate_init,\n",
        "                                        max_iter = 10)\n",
        "\n",
        "        cv_results = model_selection.cross_val_score(self.classifier,\n",
        "                                                     self.X,\n",
        "                                                     self.y,\n",
        "                                                     cv=self.kfold,\n",
        "                                                     scoring='accuracy')\n",
        "\n",
        "        return cv_results.mean()\n",
        "\n",
        "    def predecir(self, params, X_train):\n",
        "        hiddenLayerSizes, learning_rate_init, solver = self.convertParams(params)\n",
        "        self.classifier = MLPClassifier(random_state=self.randomSeed,\n",
        "                                        hidden_layer_sizes=hiddenLayerSizes,\n",
        "                                        activation='relu',\n",
        "                                        solver=solver,\n",
        "                                        batch_size=32,\n",
        "                                        learning_rate_init=learning_rate_init,\n",
        "                                        max_iter = 10)\n",
        "\n",
        "        self.classifier.fit(self.X, self.y)\n",
        "        predicted = self.classifier.predict(X_train)\n",
        "        return predicted      \n",
        "\n",
        "\n",
        "    def formatParams(self, params):\n",
        "        hiddenLayerSizes, learning_rate_init, solver = self.convertParams(params)\n",
        "        \n",
        "        return \"'hidden_layer_sizes'={}\\n \" \\\n",
        "               \"'solver'='{}'\\n \" \\\n",
        "               \"'learning_rate_init'='{}'\\n \" \\\n",
        "            .format(hiddenLayerSizes, solver, learning_rate_init)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vi-nzMGLCbF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "RANDOM_SEED = 42\n",
        "random.seed(RANDOM_SEED)\n",
        "\n",
        "BOUNDS_LOW =  [ 5,  -5, -10, -20, -3, 0]\n",
        "BOUNDS_HIGH = [15,  15,  15,  15, -1, 1.999]\n",
        "\n",
        "NUM_OF_PARAMS = len(BOUNDS_HIGH)\n",
        "\n",
        "POPULATION_SIZE = 7\n",
        "P_CROSSOVER = 0.8\n",
        "P_MUTATION = 0.2 \n",
        "MAX_GENERATIONS = 3\n",
        "HALL_OF_FAME_SIZE = 2\n",
        "CROWDING_FACTOR = 10.0 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfNLBlydLkbM",
        "colab_type": "code",
        "outputId": "eec87eee-400f-406b-f54f-8713200135cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "def classificationAccuracy(individual):\n",
        "    return test.getAccuracy(individual),\n",
        "\n",
        "test = MlpHyperparametersTest(RANDOM_SEED)\n",
        "toolbox = base.Toolbox()\n",
        "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
        "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
        "\n",
        "for i in range(NUM_OF_PARAMS):\n",
        "    toolbox.register(\"attribute_\" + str(i), random.uniform, BOUNDS_LOW[i], BOUNDS_HIGH[i])\n",
        "\n",
        "attributes = ()\n",
        "for i in range(NUM_OF_PARAMS):\n",
        "    attributes = attributes + (toolbox.__getattribute__(\"attribute_\" + str(i)),)\n",
        "\n",
        "toolbox.register(\"individualCreator\", tools.initCycle, creator.Individual, attributes, n=1)\n",
        "toolbox.register(\"populationCreator\", tools.initRepeat, list, toolbox.individualCreator)\n",
        "toolbox.register(\"evaluate\", classificationAccuracy)\n",
        "toolbox.register(\"select\", tools.selTournament, tournsize=2)\n",
        "toolbox.register(\"mate\", tools.cxSimulatedBinaryBounded, low=BOUNDS_LOW, up=BOUNDS_HIGH, eta=CROWDING_FACTOR)\n",
        "toolbox.register(\"mutate\", tools.mutPolynomialBounded, low=BOUNDS_LOW, up=BOUNDS_HIGH, eta=CROWDING_FACTOR, indpb=1.0/NUM_OF_PARAMS)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5CMuZE6JuuI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "outputId": "41d589c6-7ac1-4846-b3d3-d399b9c76db5"
      },
      "source": [
        "population = toolbox.populationCreator(n=POPULATION_SIZE)\n",
        "stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
        "stats.register(\"max\", numpy.max)\n",
        "stats.register(\"avg\", numpy.mean)\n",
        "hof = tools.HallOfFame(HALL_OF_FAME_SIZE)\n",
        "population, logbook = elitism.eaSimpleWithElitism(population,\n",
        "                                                  toolbox,\n",
        "                                                  cxpb=P_CROSSOVER,\n",
        "                                                  mutpb=P_MUTATION,\n",
        "                                                  ngen=MAX_GENERATIONS,\n",
        "                                                  stats=stats,\n",
        "                                                  halloffame=hof,\n",
        "                                                  verbose=True) "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gen\tnevals\tmax     \tavg     \n",
            "0  \t7     \t0.941257\t0.852845\n",
            "1  \t3     \t0.941257\t0.930543\n",
            "2  \t5     \t0.9413  \t0.939276\n",
            "3  \t4     \t0.941371\t0.941249\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eU3ev3SfJ_jr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "outputId": "ef4a61ad-ee50-4c08-d829-f97c684406be"
      },
      "source": [
        "print(\"- Best solution is: \\n\",\n",
        "      test.formatParams(hof.items[0]),\n",
        "      \"\\n 'accuracy' = \", test.getAccuracy(hof.items[0]))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "- Best solution is: \n",
            " 'hidden_layer_sizes'=(14,)\n",
            " 'solver'='adam'\n",
            " 'learning_rate_init'='0.002732031791094457'\n",
            "  \n",
            " 'accuracy' =  0.9413714285714285\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2s6f_TDxc3-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "outputId": "bb75fa9c-bce8-47ef-824d-47c0fcf4d926"
      },
      "source": [
        "pred = 5\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "X = numpy.vstack((x_train,x_test))\n",
        "plt.imshow(X[pred], cmap='gray')\n",
        "plt.show()                        \n",
        "\n",
        "X = X / 255.0\n",
        "X = X.reshape(X.shape[0], -1)\n",
        "predicted = test.predecir(hof.items[0], X[pred:pred+1])\n",
        "\n",
        "y_train = y_train.reshape(-1, 1)\n",
        "y_test = y_test.reshape(-1, 1)\n",
        "y = numpy.vstack((y_train,y_test))\n",
        "y = y.flatten()\n",
        "\n",
        "print(\"Predigo un\", predicted,\"cuando en realidad es un\",y[pred]) "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Predigo un [2] cuando en realidad es un 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwIs1wniw-BU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}