{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hyperparameters_grid.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/agustinsilva447/CDL/blob/master/mnist_hyperparameters.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQM78DE1Eugu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, optimizers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkDW8TaqvMzY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#función para graficar el accuracy en función de la cantidad de epochs\n",
        "def plot_accuracy_and_loss(history):\n",
        "\tplt.plot(history.history['accuracy'], label='accuracy')\n",
        "\tplt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "\tplt.xlabel('Epoch')\n",
        "\tplt.ylabel('Accuracy')\n",
        "\tplt.ylim([0.5, 1])\n",
        "\tplt.legend(loc='lower right')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tM0GeNFCvRUq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#cargando el dataset MNIST desde keras\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "#normalizando los valores de los pixels para que estén entre 0 y 1\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AetL_F0AvTqp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Todas estas son la posibles variables que se pueden autoconfigurar\n",
        "# sin embargo, solo vamos a trabajar con 3 para que las simulaciones\n",
        "# no lleven tanto tiempo. Vamos a trabajar con una red neuronal \n",
        "# con 2 hidden layers y optimizada utilizando stochastic gradient descent. \n",
        "# Vamos a tunear 3 parámetros: el learning rate, la cantidad de neuronas \n",
        "# por hidden layer y la cantidad de epochs.\n",
        "hidden_units_ = [5, 10, 15]\n",
        "hidden_layers_ = [1, 2, 3]\n",
        "solver_ = ['sgd', 'adam']\n",
        "lr_ = [0.001, 0.01, 0.1]\n",
        "#evaluamos 54 casos\n",
        "epochs_ = 10\n",
        "batch_size_ = 32\n",
        "momentum_ = 0.9\t\n",
        "nesterov_ = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n228wXQHvWkT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#inicialización de algunas variables\n",
        "test_loss = [0] * (len(hidden_units_) * len(hidden_layers_) * len(solver_) * len(lr_))\n",
        "test_acc =  [0] * (len(hidden_units_) * len(hidden_layers_) * len(solver_) * len(lr_))\n",
        "caso = 0\n",
        "max_acc = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfxBFP2kxbep",
        "colab_type": "code",
        "outputId": "10d2b8ab-9f22-4d2e-cd56-471949cb945a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 916
        }
      },
      "source": [
        "# Barremos con los distintos valores de neuronas (3), epochs (2) \n",
        "# y learning rate (3). Para cada caso calculamos la accuracy y \n",
        "# nos quedamos con el caso con el valor más alto\n",
        "for i in range(len(hidden_units_)):\n",
        "  for j in range(len(hidden_layers_)):\n",
        "    for k in range(len(lr_)):\n",
        "      for l in range(len(solver_)):\n",
        "        \n",
        "        if hidden_layers_[j] == 1:        \n",
        "          model = Sequential([\n",
        "          layers.Flatten(input_shape=(28, 28)),        \n",
        "          layers.Dense(hidden_units_[i], activation='relu'),        \n",
        "          layers.Dense(10, activation='softmax')\n",
        "          ])\n",
        "        if hidden_layers_[j] == 2:        \n",
        "          model = Sequential([\n",
        "          layers.Flatten(input_shape=(28, 28)),        \n",
        "          layers.Dense(hidden_units_[i], activation='relu'),\n",
        "          layers.Dense(hidden_units_[i], activation='relu'),        \n",
        "          layers.Dense(10, activation='softmax')\n",
        "          ])\n",
        "        if hidden_layers_[j] == 3:        \n",
        "          model = Sequential([\n",
        "          layers.Flatten(input_shape=(28, 28)),        \n",
        "          layers.Dense(hidden_units_[i], activation='relu'),\n",
        "          layers.Dense(hidden_units_[i], activation='relu'),\n",
        "          layers.Dense(hidden_units_[i], activation='relu'),        \n",
        "          layers.Dense(10, activation='softmax')\n",
        "          ])\n",
        "        \n",
        "        if solver_[l] == 'sgd':\n",
        "          optimizer = optimizers.SGD(lr=lr_[k], momentum = momentum_, nesterov=nesterov_)     \n",
        "          model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "          history = model.fit(x_train, y_train, epochs=epochs_, verbose=0, batch_size=batch_size_, validation_data=(x_test, y_test))\n",
        "          test_loss[caso], test_acc[caso] = model.evaluate(x_test, y_test, verbose=0)  \n",
        "          if test_acc[caso]>max_acc:\n",
        "            max_acc = test_acc[caso]\n",
        "            neu_opt = hidden_units_[i]\n",
        "            lay_opt = hidden_layers_[j]\n",
        "            lra_opt = lr_[k]\n",
        "            sol_opt = solver_[l]\n",
        "            hist_opt = history\n",
        "\n",
        "        if solver_[l] == 'adam':\n",
        "          optimizer = optimizers.Adam(lr=lr_[k])\n",
        "          model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])  \n",
        "          history = model.fit(x_train, y_train, epochs=epochs_, verbose=0, batch_size=batch_size_, validation_data=(x_test, y_test))\n",
        "          test_loss[caso], test_acc[caso] = model.evaluate(x_test, y_test, verbose=0)  \n",
        "          if test_acc[caso]>max_acc:\n",
        "            max_acc = test_acc[caso]\n",
        "            neu_opt = hidden_units_[i]\n",
        "            lay_opt = hidden_layers_[j]\n",
        "            lra_opt = lr_[k]\n",
        "            sol_opt = solver_[l]\n",
        "            hist_opt = history\n",
        "        print(\"Para el caso número\",caso,\"el accuracy es igual a\",test_acc[caso])\n",
        "        caso += 1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Para el caso número 0 el accuracy es igual a 0.8690999746322632\n",
            "Para el caso número 1 el accuracy es igual a 0.8974000215530396\n",
            "Para el caso número 2 el accuracy es igual a 0.9003999829292297\n",
            "Para el caso número 3 el accuracy es igual a 0.6608999967575073\n",
            "Para el caso número 4 el accuracy es igual a 0.8032000064849854\n",
            "Para el caso número 5 el accuracy es igual a 0.17679999768733978\n",
            "Para el caso número 6 el accuracy es igual a 0.866599977016449\n",
            "Para el caso número 7 el accuracy es igual a 0.8725000023841858\n",
            "Para el caso número 8 el accuracy es igual a 0.8769999742507935\n",
            "Para el caso número 9 el accuracy es igual a 0.6643999814987183\n",
            "Para el caso número 10 el accuracy es igual a 0.2912999987602234\n",
            "Para el caso número 11 el accuracy es igual a 0.20759999752044678\n",
            "Para el caso número 12 el accuracy es igual a 0.8557000160217285\n",
            "Para el caso número 13 el accuracy es igual a 0.8590999841690063\n",
            "Para el caso número 14 el accuracy es igual a 0.8781999945640564\n",
            "Para el caso número 15 el accuracy es igual a 0.8032000064849854\n",
            "Para el caso número 16 el accuracy es igual a 0.19359999895095825\n",
            "Para el caso número 17 el accuracy es igual a 0.11349999904632568\n",
            "Para el caso número 18 el accuracy es igual a 0.9226999878883362\n",
            "Para el caso número 19 el accuracy es igual a 0.9333000183105469\n",
            "Para el caso número 20 el accuracy es igual a 0.9363999962806702\n",
            "Para el caso número 21 el accuracy es igual a 0.9090999960899353\n",
            "Para el caso número 22 el accuracy es igual a 0.9150999784469604\n",
            "Para el caso número 23 el accuracy es igual a 0.3336000144481659\n",
            "Para el caso número 24 el accuracy es igual a 0.9225000143051147\n",
            "Para el caso número 25 el accuracy es igual a 0.9373000264167786\n",
            "Para el caso número 26 el accuracy es igual a 0.932699978351593\n",
            "Para el caso número 27 el accuracy es igual a 0.9265999794006348\n",
            "Para el caso número 28 el accuracy es igual a 0.21170000731945038\n",
            "Para el caso número 29 el accuracy es igual a 0.1868000030517578\n",
            "Para el caso número 30 el accuracy es igual a 0.9236999750137329\n",
            "Para el caso número 31 el accuracy es igual a 0.9366000294685364\n",
            "Para el caso número 32 el accuracy es igual a 0.9423999786376953\n",
            "Para el caso número 33 el accuracy es igual a 0.9125000238418579\n",
            "Para el caso número 34 el accuracy es igual a 0.11349999904632568\n",
            "Para el caso número 35 el accuracy es igual a 0.1665000021457672\n",
            "Para el caso número 36 el accuracy es igual a 0.9330000281333923\n",
            "Para el caso número 37 el accuracy es igual a 0.9509999752044678\n",
            "Para el caso número 38 el accuracy es igual a 0.9513999819755554\n",
            "Para el caso número 39 el accuracy es igual a 0.9420999884605408\n",
            "Para el caso número 40 el accuracy es igual a 0.9298999905586243\n",
            "Para el caso número 41 el accuracy es igual a 0.43529999256134033\n",
            "Para el caso número 42 el accuracy es igual a 0.9401999711990356\n",
            "Para el caso número 43 el accuracy es igual a 0.9501000046730042\n",
            "Para el caso número 44 el accuracy es igual a 0.9444000124931335\n",
            "Para el caso número 45 el accuracy es igual a 0.9294999837875366\n",
            "Para el caso número 46 el accuracy es igual a 0.9218000173568726\n",
            "Para el caso número 47 el accuracy es igual a 0.20829999446868896\n",
            "Para el caso número 48 el accuracy es igual a 0.942300021648407\n",
            "Para el caso número 49 el accuracy es igual a 0.9510999917984009\n",
            "Para el caso número 50 el accuracy es igual a 0.9366000294685364\n",
            "Para el caso número 51 el accuracy es igual a 0.9284999966621399\n",
            "Para el caso número 52 el accuracy es igual a 0.10620000213384628\n",
            "Para el caso número 53 el accuracy es igual a 0.1738000065088272\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kLREXQzzEK7",
        "colab_type": "code",
        "outputId": "84030974-1547-4fea-a35e-6b4a280abab0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 950
        }
      },
      "source": [
        "#mostrar resumen de todos los resultados y finalmente el caso óptimo\n",
        "caso = 0\n",
        "for i in range(len(hidden_units_)):\n",
        "\tfor j in range(len(hidden_layers_)):\n",
        "\t\tfor k in range(len(lr_)):\n",
        "\t\t\tfor l in range(len(solver_)):\n",
        "\t\t\t\tprint(\"Cantidad de layers\",hidden_layers_[j],\". Cantidad de neuronas\", hidden_units_[i],\". Solver:\",solver_[l],\". Learning rate:\", lr_[k],\". Accuracy:\", test_acc[caso])\n",
        "\t\t\t\tcaso += 1\t\t\t\t\n",
        "print(\"---------------------------------------------\")\n",
        "print(\"El Accuracy máximo es:\",max_acc,\". Para el caso con\",lay_opt,\" layers,\",neu_opt,\"cantidad de neuronas, \",sol_opt,\" y un learning rate de\",lra_opt)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cantidad de layers 1 . Cantidad de neuronas 5 . Solver: sgd . Learning rate: 0.001 . Accuracy: 0.8690999746322632\n",
            "Cantidad de layers 1 . Cantidad de neuronas 5 . Solver: adam . Learning rate: 0.001 . Accuracy: 0.8974000215530396\n",
            "Cantidad de layers 1 . Cantidad de neuronas 5 . Solver: sgd . Learning rate: 0.01 . Accuracy: 0.9003999829292297\n",
            "Cantidad de layers 1 . Cantidad de neuronas 5 . Solver: adam . Learning rate: 0.01 . Accuracy: 0.6608999967575073\n",
            "Cantidad de layers 1 . Cantidad de neuronas 5 . Solver: sgd . Learning rate: 0.1 . Accuracy: 0.8032000064849854\n",
            "Cantidad de layers 1 . Cantidad de neuronas 5 . Solver: adam . Learning rate: 0.1 . Accuracy: 0.17679999768733978\n",
            "Cantidad de layers 2 . Cantidad de neuronas 5 . Solver: sgd . Learning rate: 0.001 . Accuracy: 0.866599977016449\n",
            "Cantidad de layers 2 . Cantidad de neuronas 5 . Solver: adam . Learning rate: 0.001 . Accuracy: 0.8725000023841858\n",
            "Cantidad de layers 2 . Cantidad de neuronas 5 . Solver: sgd . Learning rate: 0.01 . Accuracy: 0.8769999742507935\n",
            "Cantidad de layers 2 . Cantidad de neuronas 5 . Solver: adam . Learning rate: 0.01 . Accuracy: 0.6643999814987183\n",
            "Cantidad de layers 2 . Cantidad de neuronas 5 . Solver: sgd . Learning rate: 0.1 . Accuracy: 0.2912999987602234\n",
            "Cantidad de layers 2 . Cantidad de neuronas 5 . Solver: adam . Learning rate: 0.1 . Accuracy: 0.20759999752044678\n",
            "Cantidad de layers 3 . Cantidad de neuronas 5 . Solver: sgd . Learning rate: 0.001 . Accuracy: 0.8557000160217285\n",
            "Cantidad de layers 3 . Cantidad de neuronas 5 . Solver: adam . Learning rate: 0.001 . Accuracy: 0.8590999841690063\n",
            "Cantidad de layers 3 . Cantidad de neuronas 5 . Solver: sgd . Learning rate: 0.01 . Accuracy: 0.8781999945640564\n",
            "Cantidad de layers 3 . Cantidad de neuronas 5 . Solver: adam . Learning rate: 0.01 . Accuracy: 0.8032000064849854\n",
            "Cantidad de layers 3 . Cantidad de neuronas 5 . Solver: sgd . Learning rate: 0.1 . Accuracy: 0.19359999895095825\n",
            "Cantidad de layers 3 . Cantidad de neuronas 5 . Solver: adam . Learning rate: 0.1 . Accuracy: 0.11349999904632568\n",
            "Cantidad de layers 1 . Cantidad de neuronas 10 . Solver: sgd . Learning rate: 0.001 . Accuracy: 0.9226999878883362\n",
            "Cantidad de layers 1 . Cantidad de neuronas 10 . Solver: adam . Learning rate: 0.001 . Accuracy: 0.9333000183105469\n",
            "Cantidad de layers 1 . Cantidad de neuronas 10 . Solver: sgd . Learning rate: 0.01 . Accuracy: 0.9363999962806702\n",
            "Cantidad de layers 1 . Cantidad de neuronas 10 . Solver: adam . Learning rate: 0.01 . Accuracy: 0.9090999960899353\n",
            "Cantidad de layers 1 . Cantidad de neuronas 10 . Solver: sgd . Learning rate: 0.1 . Accuracy: 0.9150999784469604\n",
            "Cantidad de layers 1 . Cantidad de neuronas 10 . Solver: adam . Learning rate: 0.1 . Accuracy: 0.3336000144481659\n",
            "Cantidad de layers 2 . Cantidad de neuronas 10 . Solver: sgd . Learning rate: 0.001 . Accuracy: 0.9225000143051147\n",
            "Cantidad de layers 2 . Cantidad de neuronas 10 . Solver: adam . Learning rate: 0.001 . Accuracy: 0.9373000264167786\n",
            "Cantidad de layers 2 . Cantidad de neuronas 10 . Solver: sgd . Learning rate: 0.01 . Accuracy: 0.932699978351593\n",
            "Cantidad de layers 2 . Cantidad de neuronas 10 . Solver: adam . Learning rate: 0.01 . Accuracy: 0.9265999794006348\n",
            "Cantidad de layers 2 . Cantidad de neuronas 10 . Solver: sgd . Learning rate: 0.1 . Accuracy: 0.21170000731945038\n",
            "Cantidad de layers 2 . Cantidad de neuronas 10 . Solver: adam . Learning rate: 0.1 . Accuracy: 0.1868000030517578\n",
            "Cantidad de layers 3 . Cantidad de neuronas 10 . Solver: sgd . Learning rate: 0.001 . Accuracy: 0.9236999750137329\n",
            "Cantidad de layers 3 . Cantidad de neuronas 10 . Solver: adam . Learning rate: 0.001 . Accuracy: 0.9366000294685364\n",
            "Cantidad de layers 3 . Cantidad de neuronas 10 . Solver: sgd . Learning rate: 0.01 . Accuracy: 0.9423999786376953\n",
            "Cantidad de layers 3 . Cantidad de neuronas 10 . Solver: adam . Learning rate: 0.01 . Accuracy: 0.9125000238418579\n",
            "Cantidad de layers 3 . Cantidad de neuronas 10 . Solver: sgd . Learning rate: 0.1 . Accuracy: 0.11349999904632568\n",
            "Cantidad de layers 3 . Cantidad de neuronas 10 . Solver: adam . Learning rate: 0.1 . Accuracy: 0.1665000021457672\n",
            "Cantidad de layers 1 . Cantidad de neuronas 15 . Solver: sgd . Learning rate: 0.001 . Accuracy: 0.9330000281333923\n",
            "Cantidad de layers 1 . Cantidad de neuronas 15 . Solver: adam . Learning rate: 0.001 . Accuracy: 0.9509999752044678\n",
            "Cantidad de layers 1 . Cantidad de neuronas 15 . Solver: sgd . Learning rate: 0.01 . Accuracy: 0.9513999819755554\n",
            "Cantidad de layers 1 . Cantidad de neuronas 15 . Solver: adam . Learning rate: 0.01 . Accuracy: 0.9420999884605408\n",
            "Cantidad de layers 1 . Cantidad de neuronas 15 . Solver: sgd . Learning rate: 0.1 . Accuracy: 0.9298999905586243\n",
            "Cantidad de layers 1 . Cantidad de neuronas 15 . Solver: adam . Learning rate: 0.1 . Accuracy: 0.43529999256134033\n",
            "Cantidad de layers 2 . Cantidad de neuronas 15 . Solver: sgd . Learning rate: 0.001 . Accuracy: 0.9401999711990356\n",
            "Cantidad de layers 2 . Cantidad de neuronas 15 . Solver: adam . Learning rate: 0.001 . Accuracy: 0.9501000046730042\n",
            "Cantidad de layers 2 . Cantidad de neuronas 15 . Solver: sgd . Learning rate: 0.01 . Accuracy: 0.9444000124931335\n",
            "Cantidad de layers 2 . Cantidad de neuronas 15 . Solver: adam . Learning rate: 0.01 . Accuracy: 0.9294999837875366\n",
            "Cantidad de layers 2 . Cantidad de neuronas 15 . Solver: sgd . Learning rate: 0.1 . Accuracy: 0.9218000173568726\n",
            "Cantidad de layers 2 . Cantidad de neuronas 15 . Solver: adam . Learning rate: 0.1 . Accuracy: 0.20829999446868896\n",
            "Cantidad de layers 3 . Cantidad de neuronas 15 . Solver: sgd . Learning rate: 0.001 . Accuracy: 0.942300021648407\n",
            "Cantidad de layers 3 . Cantidad de neuronas 15 . Solver: adam . Learning rate: 0.001 . Accuracy: 0.9510999917984009\n",
            "Cantidad de layers 3 . Cantidad de neuronas 15 . Solver: sgd . Learning rate: 0.01 . Accuracy: 0.9366000294685364\n",
            "Cantidad de layers 3 . Cantidad de neuronas 15 . Solver: adam . Learning rate: 0.01 . Accuracy: 0.9284999966621399\n",
            "Cantidad de layers 3 . Cantidad de neuronas 15 . Solver: sgd . Learning rate: 0.1 . Accuracy: 0.10620000213384628\n",
            "Cantidad de layers 3 . Cantidad de neuronas 15 . Solver: adam . Learning rate: 0.1 . Accuracy: 0.1738000065088272\n",
            "---------------------------------------------\n",
            "El Accuracy máximo es: 0.9513999819755554 . Para el caso con 1  layers, 15 cantidad de neuronas,  sgd  y un learning rate de 0.01\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FJqCI7rzLue",
        "colab_type": "code",
        "outputId": "69b4453f-7126-4643-c204-503429500f06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "plot_accuracy_and_loss(hist_opt)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}